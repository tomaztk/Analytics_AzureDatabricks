{"cells":[{"cell_type":"markdown","source":["## MLflow Quick Start: Tracking\nThis is a notebook based on the MLflow quick start example.  This quick start:\n* Starts an MLflow run\n* Logs parameters, metrics, and a file to the run"],"metadata":{}},{"cell_type":"markdown","source":["### Set up and attach notebook to cluster"],"metadata":{}},{"cell_type":"markdown","source":["1. Use or create a cluster with:\n  * **Databricks Runtime Version:** Databricks Runtime 6.5 ML or above \n  * **Python Version:** Python 3\n1. Install MLflow library.\n   1. Create library with Source **PyPI** and enter `mlflow`.\n1. Attach this notebook to the cluster.\n1. Microsoft docs: https://docs.microsoft.com/en-us/azure/databricks/applications/mlflow/model-registry-example"],"metadata":{}},{"cell_type":"markdown","source":["### Import MLflow"],"metadata":{}},{"cell_type":"code","source":["import mlflow"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["### Use the MLflow Tracking API\n\nUse the [MLflow Tracking API](https://www.mlflow.org/docs/latest/python_api/index.html) to start a run and log parameters, metrics, and artifacts (files) from your data science code."],"metadata":{}},{"cell_type":"code","source":["# Start an MLflow run\n\nwith mlflow.start_run():\n  # Log a parameter (key-value pair)\n  mlflow.log_param(\"param2\", 3)\n\n  # Log a metric; metrics can be updated throughout the run\n  mlflow.log_metric(\"foo\", 2, step=1)\n  mlflow.log_metric(\"foo\", 4, step=2)\n  mlflow.log_metric(\"foo\", 6, step=3)\n  mlflow.log_metric(\"foo\", 7, step=4)\n  mlflow.log_metric(\"foo\", 5, step=5)\n\n\n\n  # Log an artifact (output file)\n  with open(\"output.txt\", \"w\") as f:\n      f.write(\"Hello world!\")\n  mlflow.log_artifact(\"output.txt\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["###Load dataset\n\nThe following code loads a dataset containing weather data and power output information for a wind farm in the United States. The dataset contains wind direction, wind speed, and air temperature features sampled every six hours (once at 00:00, once at 08:00, and once at 16:00), as well as daily aggregate power output (power), over several years."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nwind_farm_data = pd.read_csv(\"https://github.com/dbczumar/model-registry-demo-notebook/raw/master/dataset/windfarm_data.csv\", index_col=0)\n\ndef get_training_data():\n  training_data = pd.DataFrame(wind_farm_data[\"2014-01-01\":\"2018-01-01\"])\n  X = training_data.drop(columns=\"power\")\n  y = training_data[\"power\"]\n  return X, y\n\ndef get_validation_data():\n  validation_data = pd.DataFrame(wind_farm_data[\"2018-01-01\":\"2019-01-01\"])\n  X = validation_data.drop(columns=\"power\")\n  y = validation_data[\"power\"]\n  return X, y\n\ndef get_weather_and_forecast():\n  format_date = lambda pd_date : pd_date.date().strftime(\"%Y-%m-%d\")\n  today = pd.Timestamp('today').normalize()\n  week_ago = today - pd.Timedelta(days=5)\n  week_later = today + pd.Timedelta(days=5)\n\n  past_power_output = pd.DataFrame(wind_farm_data)[format_date(week_ago):format_date(today)]\n  weather_and_forecast = pd.DataFrame(wind_farm_data)[format_date(week_ago):format_date(week_later)]\n  if len(weather_and_forecast) < 10:\n    past_power_output = pd.DataFrame(wind_farm_data).iloc[-10:-5]\n    weather_and_forecast = pd.DataFrame(wind_farm_data).iloc[-10:]\n\n  return weather_and_forecast.drop(columns=\"power\"), past_power_output[\"power\"]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["##Train model\n\nThe following code trains a neural network in Keras to predict power output based on the weather features in the dataset. MLflow is used to track the modelâ€™s hyperparameters, performance metrics, source code, and artifacts."],"metadata":{}},{"cell_type":"code","source":["def train_keras_model(X, y):\n  import keras\n  from keras.models import Sequential\n  from keras.layers import Dense\n\n  model = Sequential()\n  model.add(Dense(100, input_shape=(X_train.shape[-1],), activation=\"relu\", name=\"hidden_layer\"))\n  model.add(Dense(1))\n  model.compile(loss=\"mse\", optimizer=\"adam\")\n\n  model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=.2)\n  return model\n\nimport mlflow\nimport mlflow.keras\n\nX_train, y_train = get_training_data()\n\nwith mlflow.start_run():\n  # Automatically capture the model's parameters, metrics, artifacts,\n  # and source code with the `autolog()` function\n  mlflow.keras.autolog()\n\n  train_keras_model(X_train, y_train)\n  run_id = mlflow.active_run().info.run_id"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Using TensorFlow backend.\n/databricks/python/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n  from collections import Mapping, MutableMapping\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n  all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nTrain on 1168 samples, validate on 293 samples\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\nEpoch 1/100\n\r  64/1168 [&gt;.............................] - ETA: 8s - loss: 8953156.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 1s 523us/step - loss: 10197252.4658 - val_loss: 7884475.1843\nEpoch 2/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 11076982.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 27us/step - loss: 9694778.2603 - val_loss: 7392137.6894\nEpoch 3/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4689767.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 23us/step - loss: 9111937.9863 - val_loss: 6818627.6451\nEpoch 4/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3454638.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 8436636.7534 - val_loss: 6207369.3311\nEpoch 5/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 8006224.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 7735110.3493 - val_loss: 5615544.3174\nEpoch 6/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7203574.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 32us/step - loss: 7060561.4315 - val_loss: 5119782.3276\nEpoch 7/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7155351.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 38us/step - loss: 6491056.4897 - val_loss: 4760242.4710\nEpoch 8/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 8535775.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 6056796.5753 - val_loss: 4566050.8123\nEpoch 9/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5461362.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5764194.4897 - val_loss: 4499318.2048\nEpoch 10/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5456031.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 5606151.9178 - val_loss: 4507061.3208\nEpoch 11/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5776658.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 5523066.3870 - val_loss: 4548637.3669\nEpoch 12/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5560201.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 5485733.7534 - val_loss: 4560260.8549\nEpoch 13/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3604717.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 5466731.7877 - val_loss: 4587500.2799\nEpoch 14/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5552764.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 5450906.6164 - val_loss: 4595456.6297\nEpoch 15/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5218952.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5437510.5068 - val_loss: 4580707.4147\nEpoch 16/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5895680.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 36us/step - loss: 5423645.5959 - val_loss: 4572642.7116\nEpoch 17/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6516379.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5411507.5342 - val_loss: 4543279.4369\nEpoch 18/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5835678.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 5394305.1986 - val_loss: 4561706.3908\nEpoch 19/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4245831.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 38us/step - loss: 5378050.8699 - val_loss: 4544715.2235\nEpoch 20/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4722578.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 28us/step - loss: 5362748.6815 - val_loss: 4525784.6536\nEpoch 21/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6553087.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 5347547.3699 - val_loss: 4515443.3020\nEpoch 22/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5696263.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 5332171.6541 - val_loss: 4513373.1143\nEpoch 23/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6271318.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5312630.8973 - val_loss: 4477341.3686\nEpoch 24/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4423131.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5294331.0137 - val_loss: 4460322.9352\nEpoch 25/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4695107.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5273821.2397 - val_loss: 4451978.3447\nEpoch 26/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6082314.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 29us/step - loss: 5251230.5616 - val_loss: 4430679.7065\nEpoch 27/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4835578.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 5227697.6027 - val_loss: 4432040.5444\nEpoch 28/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4349787.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 5202105.1301 - val_loss: 4387572.8396\nEpoch 29/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5107061.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 5172167.6027 - val_loss: 4363354.7355\nEpoch 30/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7742810.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 5145115.1781 - val_loss: 4355839.2184\nEpoch 31/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3855896.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 27us/step - loss: 5108849.8151 - val_loss: 4303869.0631\nEpoch 32/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5731745.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 5077114.2466 - val_loss: 4271516.3959\nEpoch 33/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6116817.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 5039858.7877 - val_loss: 4268300.4420\nEpoch 34/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7441658.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 5006393.6712 - val_loss: 4224969.5512\nEpoch 35/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7769437.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 4965399.5068 - val_loss: 4194203.3294\nEpoch 36/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4303080.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4938134.4521 - val_loss: 4125371.9198\nEpoch 37/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3562475.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 4886406.7808 - val_loss: 4138092.4863\nEpoch 38/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6999464.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 4843571.4795 - val_loss: 4100966.7799\nEpoch 39/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5486635.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 25us/step - loss: 4799374.2260 - val_loss: 4035138.2133\nEpoch 40/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 6094175.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 4757007.6096 - val_loss: 4025116.6177\nEpoch 41/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3952483.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4713188.7945 - val_loss: 3966066.4829\nEpoch 42/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3142013.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 27us/step - loss: 4660707.5822 - val_loss: 3937198.4249\nEpoch 43/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4652409.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 4611293.1096 - val_loss: 3921507.5358\nEpoch 44/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3501625.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 23us/step - loss: 4563976.1233 - val_loss: 3863381.3345\nEpoch 45/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7126195.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4511440.1233 - val_loss: 3818698.9352\nEpoch 46/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4792665.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4459678.8082 - val_loss: 3756157.0392\nEpoch 47/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4053449.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4406635.6712 - val_loss: 3726141.8464\nEpoch 48/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4885465.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 4353213.1370 - val_loss: 3688959.4778\nEpoch 49/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4926656.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4294702.6199 - val_loss: 3636666.3771\nEpoch 50/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4746367.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 4241907.4658 - val_loss: 3572945.0119\nEpoch 51/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3220164.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 4182197.8082 - val_loss: 3530921.2048\nEpoch 52/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3091107.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 4132676.7945 - val_loss: 3526421.9795\nEpoch 53/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 7054800.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 30us/step - loss: 4057250.1096 - val_loss: 3407377.8549\nEpoch 54/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3667803.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 4011670.9538 - val_loss: 3406259.2457\nEpoch 55/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2212981.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 3948253.2466 - val_loss: 3326067.3208\nEpoch 56/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4844189.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 3896032.6027 - val_loss: 3313245.8055\nEpoch 57/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 5194611.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 3815404.7354 - val_loss: 3203350.7440\nEpoch 58/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4751652.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 3752654.0582 - val_loss: 3178096.3208\nEpoch 59/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4098538.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 3686485.6164 - val_loss: 3117810.9983\nEpoch 60/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3087438.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 3620101.4589 - val_loss: 3082622.2457\nEpoch 61/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4757779.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 3567200.0822 - val_loss: 3038160.1587\nEpoch 62/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4818020.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 3494337.5342 - val_loss: 2942200.9488\nEpoch 63/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 4294273.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 3427328.4264 - val_loss: 2892312.3498\nEpoch 64/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2453091.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 3359932.1575 - val_loss: 2839221.0631\nEpoch 65/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3628982.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 3308083.4452 - val_loss: 2794369.2935\nEpoch 66/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2590884.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 3223320.0342 - val_loss: 2729082.6280\nEpoch 67/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2736200.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 23us/step - loss: 3152930.2466 - val_loss: 2686465.2406\nEpoch 68/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3448893.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 3085308.7945 - val_loss: 2610354.9881\nEpoch 69/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2649093.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 3019466.9452 - val_loss: 2554916.3294\nEpoch 70/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2828917.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 2948627.2414 - val_loss: 2481572.9949\nEpoch 71/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2808390.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 27us/step - loss: 2881846.9075 - val_loss: 2428383.2918\nEpoch 72/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3192405.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 27us/step - loss: 2813725.5616 - val_loss: 2366115.1263\nEpoch 73/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2718595.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 2746641.0274 - val_loss: 2311927.7671\nEpoch 74/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2337007.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 2677443.3973 - val_loss: 2257561.0188\nEpoch 75/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2210372.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 23us/step - loss: 2610877.2551 - val_loss: 2199160.4599\nEpoch 76/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2784973.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 2542086.3151 - val_loss: 2123225.9437\nEpoch 77/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3076789.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 2478133.6918 - val_loss: 2063109.8746\nEpoch 78/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 3070228.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 24us/step - loss: 2410129.0274 - val_loss: 2019462.1468\nEpoch 79/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2151016.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 19us/step - loss: 2346625.6199 - val_loss: 1946017.5589\nEpoch 80/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2164360.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 31us/step - loss: 2278653.6284 - val_loss: 1908812.2253\nEpoch 81/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2767546.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 2214286.9041 - val_loss: 1857921.1297\nEpoch 82/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2931841.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 2148806.4760 - val_loss: 1775377.1442\nEpoch 83/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 2654298.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 2083665.5479 - val_loss: 1723201.2150\nEpoch 84/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1365721.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 23us/step - loss: 2027128.6233 - val_loss: 1696231.5896\nEpoch 85/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1785723.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 1963570.6130 - val_loss: 1623796.5597\nEpoch 86/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1298712.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 1899439.1404 - val_loss: 1559259.9172\nEpoch 87/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1630114.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 1845332.1096 - val_loss: 1527938.0375\nEpoch 88/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1581853.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 1776905.5822 - val_loss: 1456555.1271\nEpoch 89/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1242655.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 1718140.5171 - val_loss: 1414427.7892\nEpoch 90/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1911288.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 21us/step - loss: 1661623.1438 - val_loss: 1348932.4411\nEpoch 91/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1437076.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 27us/step - loss: 1604237.6747 - val_loss: 1305243.2065\nEpoch 92/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1319761.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 25us/step - loss: 1547960.1370 - val_loss: 1251359.1962\nEpoch 93/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1239747.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 1503444.7021 - val_loss: 1195283.8358\nEpoch 94/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 995384.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 23us/step - loss: 1442294.7800 - val_loss: 1180618.0303\nEpoch 95/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 897335.3125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 1394304.3271 - val_loss: 1126847.5239\nEpoch 96/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1930118.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 26us/step - loss: 1346011.8082 - val_loss: 1071529.3767\nEpoch 97/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1105466.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 1294225.9015 - val_loss: 1062472.7385\nEpoch 98/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1633986.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 1250421.9760 - val_loss: 982272.9949\nEpoch 99/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1462067.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 20us/step - loss: 1206761.6438 - val_loss: 946091.3379\nEpoch 100/100\n\r  64/1168 [&gt;.............................] - ETA: 0s - loss: 1189961.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1168/1168 [==============================] - 0s 22us/step - loss: 1155402.6130 - val_loss: 921010.1826\n</div>"]}}],"execution_count":11}],"metadata":{"name":"MLflow Quick Start (Python)","notebookId":2710516509016252},"nbformat":4,"nbformat_minor":0}
